name: Phase 4 Expert - CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'Phase-4-Expert/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'Phase-4-Expert/**'
  workflow_dispatch:

env:
  JAVA_VERSION: '17'
  MAVEN_OPTS: -Xmx1024m

jobs:
  # Build and Test E-commerce Microservices Platform
  test-ecommerce-platform:
    name: Test E-commerce Microservices Platform
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        service: [discovery-service, api-gateway, user-service, product-service, order-service, payment-service, notification-service]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Cache Maven dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2
        
    - name: Build and test ${{ matrix.service }}
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform/${{ matrix.service }}
      run: |
        mvn clean compile test -B
        
    - name: Generate test report for ${{ matrix.service }}
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform/${{ matrix.service }}
      run: |
        mvn surefire-report:report
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.service }}
        path: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform/${{ matrix.service }}/target/surefire-reports/

  # Build and Test Performance Testing Tools
  test-performance-tools:
    name: Test Performance Testing Tools
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        tool: [BenchmarkingTool, MemoryAnalyzer]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Cache Maven dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2
        
    - name: Build and test ${{ matrix.tool }}
      working-directory: Phase-4-Expert/Performance-Testing/${{ matrix.tool }}
      run: |
        mvn clean compile test -B
        
    - name: Generate test report for ${{ matrix.tool }}
      working-directory: Phase-4-Expert/Performance-Testing/${{ matrix.tool }}
      run: |
        mvn surefire-report:report
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.tool }}
        path: Phase-4-Expert/Performance-Testing/${{ matrix.tool }}/target/surefire-reports/

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test-ecommerce-platform, test-performance-tools]
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: rootpassword
          MYSQL_DATABASE: testdb
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Cache Maven dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2
        
    - name: Start Discovery Service
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform/discovery-service
      run: |
        timeout 300 mvn spring-boot:run &
        DISCOVERY_PID=$!
        echo "Discovery service PID: $DISCOVERY_PID"
        
        # Wait for service to be ready with retry logic
        for i in {1..30}; do
          if curl -f http://localhost:8761/actuator/health >/dev/null 2>&1; then
            echo "Discovery service is ready"
            break
          fi
          echo "Waiting for discovery service... attempt $i/30"
          sleep 10
        done
        
        # Final health check
        curl -f http://localhost:8761/actuator/health || (echo "Discovery service failed to start" && exit 1)
      
    - name: Start API Gateway
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform/api-gateway
      run: |
        timeout 300 mvn spring-boot:run &
        GATEWAY_PID=$!
        echo "API Gateway PID: $GATEWAY_PID"
        
        # Wait for service to be ready with retry logic
        for i in {1..20}; do
          if curl -f http://localhost:8080/actuator/health >/dev/null 2>&1; then
            echo "API Gateway is ready"
            break
          fi
          echo "Waiting for API Gateway... attempt $i/20"
          sleep 10
        done
        
        # Final health check
        curl -f http://localhost:8080/actuator/health || (echo "API Gateway failed to start" && exit 1)
        
    - name: Run Memory Analyzer
      working-directory: Phase-4-Expert/Performance-Testing/MemoryAnalyzer
      run: |
        timeout 300 mvn spring-boot:run &
        MEMORY_PID=$!
        echo "Memory Analyzer PID: $MEMORY_PID"
        
        # Wait for service to be ready with retry logic
        for i in {1..15}; do
          if curl -f http://localhost:8090/memory-analyzer/actuator/health >/dev/null 2>&1; then
            echo "Memory Analyzer is ready"
            break
          fi
          echo "Waiting for Memory Analyzer... attempt $i/15"
          sleep 10
        done
        
        # Final health check
        curl -f http://localhost:8090/memory-analyzer/actuator/health || (echo "Memory Analyzer failed to start" && exit 1)
        
    - name: Run Enhanced Benchmarking Tool
      working-directory: Phase-4-Expert/Performance-Testing/BenchmarkingTool
      run: |
        timeout 300 mvn spring-boot:run &
        BENCHMARK_PID=$!
        echo "Benchmarking Tool PID: $BENCHMARK_PID"
        
        # Wait for service to be ready with retry logic
        for i in {1..15}; do
          if curl -f http://localhost:8091/api/benchmark/health >/dev/null 2>&1; then
            echo "Benchmarking Tool is ready"
            break
          fi
          echo "Waiting for Benchmarking Tool... attempt $i/15"
          sleep 10
        done
        
        # Final health check
        curl -f http://localhost:8091/api/benchmark/health || (echo "Benchmarking Tool failed to start" && exit 1)
        
    - name: Run integration tests
      run: |
        echo "Running end-to-end integration tests..."
        
        # Test Memory Analyzer API with error handling
        echo "Testing Memory Analyzer API..."
        if ! curl -f -X GET "http://localhost:8090/memory-analyzer/api/memory/current"; then
          echo "Memory Analyzer API test failed"
          exit 1
        fi
        
        # Test Enhanced Benchmarking Tool API with error handling  
        echo "Testing Benchmarking Tool API..."
        if ! curl -f -X GET "http://localhost:8091/api/benchmark/scenarios"; then
          echo "Benchmarking Tool API test failed"
          exit 1
        fi
        
        # Test quick performance test with error handling
        echo "Testing quick performance test..."
        if ! curl -f -X POST "http://localhost:8091/api/benchmark/quick-test?host=localhost&endpoint=/actuator/health&threads=5"; then
          echo "Quick performance test failed"
          exit 1
        fi
        
        echo "All integration tests passed successfully!"

  # Performance Regression Tests
  performance-tests:
    name: Performance Regression Tests
    runs-on: ubuntu-latest
    needs: [integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Run Memory Analysis
      working-directory: Phase-4-Expert/Performance-Testing/MemoryAnalyzer
      run: |
        timeout 300 mvn spring-boot:run &
        MEMORY_PID=$!
        echo "Memory Analyzer PID: $MEMORY_PID"
        
        # Wait for service to be ready
        for i in {1..20}; do
          if curl -f http://localhost:8090/memory-analyzer/actuator/health >/dev/null 2>&1; then
            echo "Memory Analyzer is ready for performance testing"
            break
          fi
          echo "Waiting for Memory Analyzer... attempt $i/20"
          sleep 10
        done
        
        # Run memory analysis tests with error handling
        echo "Running memory analysis tests..."
        if curl -f -X GET "http://localhost:8090/memory-analyzer/api/memory/current" > memory-results.json; then
          echo "Memory current test completed successfully"
        else
          echo "Memory current test failed"
          exit 1
        fi
        
        if curl -f -X GET "http://localhost:8090/memory-analyzer/api/memory/health" > memory-health.json; then
          echo "Memory health test completed successfully"
        else
          echo "Memory health test failed"
          exit 1
        fi
        
    - name: Run Database Performance Tests
      working-directory: Phase-4-Expert/Performance-Testing/BenchmarkingTool
      run: |
        timeout 300 mvn spring-boot:run &
        BENCHMARK_PID=$!
        echo "Benchmarking Tool PID: $BENCHMARK_PID"
        
        # Wait for service to be ready
        for i in {1..20}; do
          if curl -f http://localhost:8091/api/benchmark/health >/dev/null 2>&1; then
            echo "Benchmarking Tool is ready for performance testing"
            break
          fi
          echo "Waiting for Benchmarking Tool... attempt $i/20"
          sleep 10
        done
        
        # Run database performance test with error handling
        echo "Running database performance test..."
        if curl -f -X POST "http://localhost:8091/api/benchmark/database/run-sync" \
          -H "Content-Type: application/json" \
          -d '{"testName":"CI Pipeline Database Test","insertCount":100,"selectCount":50}' \
          > database-performance-results.json; then
          echo "Database performance test completed successfully"
        else
          echo "Database performance test failed"
          exit 1
        fi
        
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-test-results
        path: |
          memory-results.json
          memory-health.json
          database-performance-results.json

  # Security Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run OWASP Dependency Check
      uses: dependency-check/Dependency-Check_Action@main
      with:
        project: 'Phase-4-Expert'
        path: 'Phase-4-Expert'
        format: 'JSON'
      continue-on-error: true
        
    - name: Upload security scan results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-scan-results
        path: reports/

  # Build Docker Images (if Dockerfiles exist)
  build-docker-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test-ecommerce-platform, test-performance-tools]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Build E-commerce Platform Images
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform
      run: |
        if [ -f docker-compose.yml ]; then
          echo "Building E-commerce platform Docker images..."
          if docker-compose build --no-cache; then
            echo "E-commerce platform images built successfully"
          else
            echo "Failed to build E-commerce platform images"
            exit 1
          fi
        else
          echo "No docker-compose.yml found, skipping docker build"
        fi
        
    - name: Test Docker Deployment
      working-directory: Phase-4-Expert/Advanced-Spring-Microservices/EcommercePlatform
      run: |
        if [ -f docker-compose.yml ]; then
          echo "Testing Docker deployment..."
          if docker-compose up -d; then
            echo "Docker services started successfully"
            sleep 60
            docker-compose ps
            
            # Check if services are healthy
            echo "Checking service health..."
            docker-compose ps --format "table {{.Name}}\t{{.State}}"
            
            echo "Stopping Docker services..."
            docker-compose down
          else
            echo "Failed to start Docker services"
            docker-compose down
            exit 1
          fi
        else
          echo "No docker-compose.yml found, skipping docker deployment test"
        fi

  # Generate Reports
  generate-reports:
    name: Generate Reports
    runs-on: ubuntu-latest
    needs: [integration-tests, performance-tests, security-scan]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      
    - name: Generate comprehensive report
      run: |
        echo "# Phase 4 Expert - CI/CD Pipeline Report" > pipeline-report.md
        echo "" >> pipeline-report.md
        echo "## Build Summary" >> pipeline-report.md
        echo "- E-commerce Platform: ${{ needs.test-ecommerce-platform.result }}" >> pipeline-report.md
        echo "- Performance Tools: ${{ needs.test-performance-tools.result }}" >> pipeline-report.md
        echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> pipeline-report.md
        echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> pipeline-report.md
        echo "- Security Scan: ${{ needs.security-scan.result }}" >> pipeline-report.md
        echo "" >> pipeline-report.md
        echo "## Test Results" >> pipeline-report.md
        echo "All test artifacts have been uploaded for review." >> pipeline-report.md
        
    - name: Upload pipeline report
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-report
        path: pipeline-report.md

  # Deployment (to staging environment)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [integration-tests, performance-tests]
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Build deployment artifacts
      working-directory: Phase-4-Expert
      run: |
        echo "Building all Phase 4 components for deployment..."
        build_failed=false
        
        # Build all Phase 4 components with error handling
        find . -name "pom.xml" -exec dirname {} \; | while read dir; do
          echo "Building $dir"
          if (cd "$dir" && mvn clean package -DskipTests); then
            echo "✅ Successfully built $dir"
          else
            echo "❌ Failed to build $dir"
            build_failed=true
          fi
        done
        
        if [ "$build_failed" = true ]; then
          echo "Some components failed to build"
          exit 1
        fi
        
    - name: Simulate deployment
      run: |
        echo "Deploying Phase 4 Expert components to staging environment..."
        
        # Simulate deployment checks
        components=("Memory Analyzer" "Enhanced Benchmarking Tool" "E-commerce Microservices Platform")
        for component in "${components[@]}"; do
          echo "Deploying $component..."
          sleep 2  # Simulate deployment time
          echo "- $component deployed ✅"
        done
        
        echo "Staging deployment completed successfully!"
        echo "All Phase 4 Expert components are now available in staging environment."